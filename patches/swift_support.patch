diff --git a/refresh.template.py b/refresh.template.py
index 38303a7..c616ae4 100644
--- a/refresh.template.py
+++ b/refresh.template.py
@@ -555,13 +555,41 @@ def _get_headers(compile_action, source_path: str):
 _get_headers.has_logged = False
 
 
+def _warn_if_file_doesnt_exist(source_file):
+    if not os.path.isfile(source_file):
+        if not _warn_if_file_doesnt_exist.has_logged_missing_file_error: # Just log once; subsequent messages wouldn't add anything.
+            _warn_if_file_doesnt_exist.has_logged_missing_file_error = True
+            log_warning(f""">>> A source file you compile doesn't (yet) exist: {source_file}
+    It's probably a generated file, and you haven't yet run a build to generate it.
+    That's OK; your code doesn't even have to compile for this tool to work.
+    If you can, though, you might want to run a build of your code.
+        That way everything is generated, browsable and indexed for autocomplete.
+    However, if you have *already* built your code, and generated the missing file...
+        Please make sure you're supplying this tool with the same flags you use to build.
+        You can either use a refresh_compile_commands rule or the special -- syntax. Please see the README.
+        [Supplying flags normally won't work. That just causes this tool to be built with those flags.]
+    Continuing gracefully...""")
+        return True
+    return False
+_warn_if_file_doesnt_exist.has_logged_missing_file_error = False
+
+
 def _get_files(compile_action):
     """Gets the ({source files}, {header files}) clangd should be told the command applies to."""
 
+    # If we've got swift action just return sources
+    if compile_action.mnemonic == 'SwiftCompile':
+        source_files = set(arg for arg in compile_action.arguments if arg.endswith('.swift'))
+        for source_file in source_files:
+            _warn_if_file_doesnt_exist(source_file)
+
+        return source_files, set()
+
+    # Getting the source file is a little t
     # Getting the source file is a little trickier than it might seem.
 
     # First, we do the obvious thing: Filter args to those that look like source files.
-    source_file_candidates = [arg for arg in compile_action.arguments if not arg.startswith('-') and arg.endswith(_get_files.source_extensions)]
+    source_file_candidates = [arg for arg in compile_action.arguments if not arg.startswith('-') and arg.endswith(_get_files.c_family_source_extensions)]
     assert source_file_candidates, f"No source files found in compile args: {compile_action.arguments}.\nPlease file an issue with this information!"
     source_file = source_file_candidates[0]
 
@@ -589,22 +617,10 @@ def _get_files(compile_action):
             source_index = compile_action.arguments.index('/c') + 1
 
         source_file = compile_action.arguments[source_index]
-        assert source_file.endswith(_get_files.source_extensions), f"Source file candidate, {source_file}, seems to be wrong.\nSelected from {compile_action.arguments}.\nPlease file an issue with this information!"
+        assert source_file.endswith(_get_files.c_family_source_extensions), f"Source file candidate, {source_file}, seems to be wrong.\nSelected from {compile_action.arguments}.\nPlease file an issue with this information!"
 
     # Warn gently about missing files
-    if not os.path.isfile(source_file):
-        if not _get_files.has_logged_missing_file_error: # Just log once; subsequent messages wouldn't add anything.
-            _get_files.has_logged_missing_file_error = True
-            log_warning(f""">>> A source file you compile doesn't (yet) exist: {source_file}
-    It's probably a generated file, and you haven't yet run a build to generate it.
-    That's OK; your code doesn't even have to compile for this tool to work.
-    If you can, though, you might want to run a build of your code with --keep_going.
-        That way everything possible is generated, browsable and indexed for autocomplete.
-    However, if you have *already* built your code, and generated the missing file...
-        Please make sure you're supplying this tool with the same flags you use to build.
-        You can either use a refresh_compile_commands rule or the special -- syntax. Please see the README.
-        [Supplying flags normally won't work. That just causes this tool to be built with those flags.]
-    Continuing gracefully...""")
+    if _warn_if_file_doesnt_exist(source_file):
         return {source_file}, set()
 
     # Note: We need to apply commands to headers and sources.
@@ -633,7 +649,6 @@ def _get_files(compile_action):
         compile_action.arguments.insert(1, lang_flag)
 
     return {source_file}, header_files
-_get_files.has_logged_missing_file_error = False
 # Setup extensions and flags for the whole C-language family.
 # Clang has a list: https://github.com/llvm/llvm-project/blob/b9f3b7f89a4cb4cf541b7116d9389c73690f78fa/clang/lib/Driver/Types.cpp#L293
 _get_files.c_source_extensions = ('.c', '.i')
@@ -645,7 +660,6 @@ _get_files.opencl_source_extensions = ('.cl',)
 _get_files.openclxx_source_extensions = ('.clcpp',)
 _get_files.assembly_source_extensions = ('.s', '.asm')
 _get_files.assembly_needing_c_preprocessor_source_extensions = ('.S',)
-_get_files.source_extensions = _get_files.c_source_extensions + _get_files.cpp_source_extensions + _get_files.objc_source_extensions + _get_files.objcpp_source_extensions + _get_files.cuda_source_extensions + _get_files.opencl_source_extensions + _get_files.openclxx_source_extensions + _get_files.assembly_source_extensions + _get_files.assembly_needing_c_preprocessor_source_extensions
 _get_files.extensions_to_language_args = { # Note that clangd fails on the --language or -ObjC or -ObjC++ forms. See https://github.com/clangd/clangd/issues/1173#issuecomment-1226847416
     _get_files.c_source_extensions: '-xc',
     _get_files.cpp_source_extensions: '-xc++',
@@ -658,6 +672,8 @@ _get_files.extensions_to_language_args = { # Note that clangd fails on the --lan
     _get_files.assembly_needing_c_preprocessor_source_extensions: '-xassembler-with-cpp',
 }
 _get_files.extensions_to_language_args = {ext : flag for exts, flag in _get_files.extensions_to_language_args.items() for ext in exts} # Flatten map for easier use
+_get_files.c_family_source_extensions = _get_files.c_source_extensions + _get_files.cpp_source_extensions + _get_files.objc_source_extensions + _get_files.objcpp_source_extensions + _get_files.cuda_source_extensions + _get_files.opencl_source_extensions + _get_files.openclxx_source_extensions + _get_files.assembly_source_extensions + _get_files.assembly_needing_c_preprocessor_source_extensions
+_get_files.source_extensions = _get_files.c_family_source_extensions + ('.swift',)
 
 
 @functools.lru_cache(maxsize=None)
@@ -678,17 +694,25 @@ def _get_apple_SDKROOT(SDK_name: str):
     # Traditionally stored in SDKROOT environment variable, but not provided by Bazel. See https://github.com/bazelbuild/bazel/issues/12852
 
 
-def _get_apple_platform(compile_args: typing.List[str]):
+def _get_apple_platform(compile_action):
     """Figure out which Apple platform a command is for.
 
     Is the name used by Xcode in the SDK files, not the marketing name.
     e.g. iPhoneOS, not iOS.
     """
     # A bit gross, but Bazel specifies the platform name in one of the include paths, so we mine it from there.
+    compile_args = compile_action.arguments
     for arg in compile_args:
         match = re.search('/Platforms/([a-zA-Z]+).platform/Developer/', arg)
         if match:
             return match.group(1)
+    if getattr(compile_action, 'environmentVariables', None):
+        match = next(
+            filter(lambda x: x.key == "APPLE_SDK_PLATFORM", compile_action.environmentVariables),
+            None
+        )
+        if match:
+            return match.value
     return None
 
 
@@ -700,18 +724,21 @@ def _get_apple_DEVELOPER_DIR():
     # Traditionally stored in DEVELOPER_DIR environment variable, but not provided by Bazel. See https://github.com/bazelbuild/bazel/issues/12852
 
 
-def _apple_platform_patch(compile_args: typing.List[str]):
+def _apple_platform_patch(compile_action):
     """De-Bazel the command into something clangd can parse.
 
     This function has fixes specific to Apple platforms, but you should call it on all platforms. It'll determine whether the fixes should be applied or not.
     """
+    compile_args = compile_action.arguments
     # Bazel internal environment variable fragment that distinguishes Apple platforms that need unwrapping.
         # Note that this occurs in the Xcode-installed wrapper, but not the CommandLineTools wrapper, which works fine as is.
     if any('__BAZEL_XCODE_' in arg for arg in compile_args):
         # Undo Bazel's Apple platform compiler wrapping.
         # Bazel wraps the compiler as `external/local_config_cc/wrapped_clang` and exports that wrapped compiler in the proto. However, we need a clang call that clangd can introspect. (See notes in "how clangd uses compile_commands.json" in ImplementationReadme.md for more.)
         # Removing the wrapper is also important because Bazel's Xcode (but not CommandLineTools) wrapper crashes if you don't specify particular environment variables (replaced below). We'd need the wrapper to be invokable by clangd's --query-driver if we didn't remove the wrapper.
-        compile_args[0] = 'clang'
+
+        if compile_action.mnemonic != 'SwiftCompile':
+            compile_args[0] = 'clang'
 
         # We have to manually substitute out Bazel's macros so clang can parse the command
         # Code this mirrors is in https://github.com/bazelbuild/bazel/blob/master/tools/osx/crosstool/wrapped_clang.cc
@@ -720,15 +747,41 @@ def _apple_platform_patch(compile_args: typing.List[str]):
         # We also have to manually figure out the values of SDKROOT and DEVELOPER_DIR, since they're missing from the environment variables Bazel provides.
         # Filed Bazel issue about the missing environment variables: https://github.com/bazelbuild/bazel/issues/12852
         compile_args = [arg.replace('__BAZEL_XCODE_DEVELOPER_DIR__', _get_apple_DEVELOPER_DIR()) for arg in compile_args]
-        apple_platform = _get_apple_platform(compile_args)
+        apple_platform = _get_apple_platform(compile_action)
         assert apple_platform, f"Apple platform not detected in CMD: {compile_args}"
         compile_args = [arg.replace('__BAZEL_XCODE_SDKROOT__', _get_apple_SDKROOT(apple_platform)) for arg in compile_args]
 
     return compile_args
 
 
-def _all_platform_patch(compile_args: typing.List[str]):
+def _swift_patch(compile_action):
+    """De-Bazel the command into something sourecekit-lsp can parse.
+
+    This function has fixes specific to Swift, but you should call it on all platforms. It'll determine whether the fixes should be applied or not.
+    """
+
+    compile_args = compile_action.arguments
+    if compile_action.mnemonic == 'SwiftCompile':
+        # rules_swift add a worker for wrapping if enable --persistent_worker flag (https://bazel.build/remote/persistent)
+        # https://github.com/bazelbuild/rules_swift/blob/master/swift/internal/actions.bzl#L236
+        # We need to remove it (build_bazel_rules_swift/tools/worker/worker)
+        while len(compile_args) > 0 and (not 'swiftc' in compile_args[0]):
+            compile_args.pop(0)
+
+        assert len(compile_args) > 0, "No compiler found in swift_path"
+        compile_args[0] = 'swiftc'
+
+        # Remove -Xwrapped-swift introduced by rules_swift
+        compile_args = [arg for arg in compile_args if not arg.startswith('-Xwrapped-swift')]
+
+    return compile_args
+
+
+def _all_platform_patch(compile_action):
     """Apply de-Bazeling fixes to the compile command that are shared across target platforms."""
+
+    compile_args = compile_action.arguments
+
     # clangd writes module cache files to the wrong place
     # Without this fix, you get tons of module caches dumped into the VSCode root folder.
     # Filed clangd issue at: https://github.com/clangd/clangd/issues/655
@@ -763,7 +816,7 @@ def _all_platform_patch(compile_args: typing.List[str]):
     return compile_args
 
 
-def _get_cpp_command_for_files(args):
+def _get_command_for_files(args):
     """Reformat compile_action into a compile command clangd can understand.
 
     Undo Bazel-isms and figures out which files clangd should apply the command to.
@@ -773,8 +826,9 @@ def _get_cpp_command_for_files(args):
         return set(), set(), []
 
     # Patch command by platform
-    compile_action.arguments = _all_platform_patch(compile_action.arguments)
-    compile_action.arguments = _apple_platform_patch(compile_action.arguments)
+    compile_action.arguments = _all_platform_patch(compile_action)
+    compile_action.arguments = _apple_platform_patch(compile_action)
+    compile_action.arguments = _swift_patch(compile_action)
     # Android and Linux and grailbio LLVM toolchains: Fine as is; no special patching needed.
 
     source_files, header_files = _get_files(compile_action)
@@ -809,7 +863,7 @@ def _convert_compile_commands(aquery_output, should_stop_lambda):
         max_workers=min(32, (os.cpu_count() or 1) + 4) # Backport. Default in MIN_PY=3.8. See "using very large resources implicitly on many-core machines" in https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor
     ) as threadpool:
         event = threading.Event()
-        outputs = threadpool.map(_get_cpp_command_for_files, map(lambda action: (action, event, should_stop_lambda), aquery_output.actions))
+        outputs = threadpool.map(_get_command_for_files, map(lambda action: (action, event, should_stop_lambda), aquery_output.actions))
     # Yield as compile_commands.json entries
     header_files_already_written = set()
     for source_files, header_files, compile_command_args in outputs:
@@ -855,7 +909,7 @@ def _get_commands(target: str, flags: str):
             # Aquery docs if you need em: https://docs.bazel.build/versions/master/aquery.html
             # Aquery output proto reference: https://github.com/bazelbuild/bazel/blob/master/src/main/protobuf/analysis_v2.proto
             # One bummer, not described in the docs, is that aquery filters over *all* actions for a given target, rather than just those that would be run by a build to produce a given output. This mostly isn't a problem, but can sometimes surface extra, unnecessary, misconfigured actions. Chris has emailed the authors to discuss and filed an issue so anyone reading this could track it: https://github.com/bazelbuild/bazel/issues/14156.
-            f"mnemonic('(Objc|Cpp)Compile', {target_statment})",
+            f"mnemonic('(Objc|Cpp|Swift)Compile', {target_statment})",
             # We switched to jsonproto instead of proto because of https://github.com/bazelbuild/bazel/issues/13404. We could change back when fixed--reverting most of the commit that added this line and tweaking the build file to depend on the target in that issue. That said, it's kinda nice to be free of the dependency, unless (OPTIMNOTE) jsonproto becomes a performance bottleneck compated to binary protos.
             '--output=jsonproto',
             # We'll disable artifact output for efficiency, since it's large and we don't use them. Small win timewise, but dramatically less json output from aquery.
diff --git a/x.patch b/x.patch
new file mode 100644
index 0000000..4dd87eb
--- /dev/null
+++ b/x.patch
@@ -0,0 +1,515 @@
+diff --git a/refresh.template.py b/refresh.template.py
+index 3cb871f..7b5f84f 100644
+--- a/refresh.template.py
++++ b/refresh.template.py
+@@ -3,8 +3,9 @@ As a template, this file helps implement the refresh_compile_commands rule and i
+ 
+ Interface (after template expansion):
+ - `bazel run` to regenerate compile_commands.json, so autocomplete (and any other clang tooling!) reflect the latest Bazel build files.
+-    - No arguments are needed; info from the rule baked into the template expansion.
++    - No arguments are needed; info from the rule is baked into the template expansion.
+         - Any arguments passed are interpreted as arguments needed for the builds being analyzed.
++        - The one exception is --file=<file_target>, which can be used to update commands for just one file. This is intended for programmatic use from editor plugins.
+     - Requires being run under Bazel so we can access the workspace root environment variable.
+ - Output: a compile_commands.json in the workspace root that clang tooling (or you!) can look at to figure out how files are being compiled by Bazel
+     - Crucially, this output is de-Bazeled; The result is a command that could be run from the workspace root directly, with no Bazel-specific requirements, environment variables, etc.
+@@ -34,6 +35,8 @@ import tempfile
+ import time
+ import types
+ import typing # MIN_PY=3.9: Switch e.g. typing.List[str] -> list[str]
++import threading
++import itertools
+ 
+ 
+ @enum.unique
+@@ -177,6 +180,7 @@ def _get_cached_adjusted_modified_time(path: str):
+ # Roughly 1 year into the future. This is safely below bazel's 10 year margin, but large enough that no sane normal file should be past this.
+ BAZEL_INTERNAL_SOURCE_CUTOFF = time.time() + 60*60*24*365
+ 
++BAZEL_INTERNAL_MAX_HEADER_SEARCH_COUNT = 500
+ 
+ def _get_headers_gcc(compile_args: typing.List[str], source_path: str, action_key: str):
+     """Gets the headers used by a particular compile command that uses gcc arguments formatting (including clang.)
+@@ -551,13 +555,41 @@ def _get_headers(compile_action, source_path: str):
+ _get_headers.has_logged = False
+ 
+ 
++def _warn_if_file_doesnt_exist(source_file):
++    if not os.path.isfile(source_file):
++        if not _warn_if_file_doesnt_exist.has_logged_missing_file_error: # Just log once; subsequent messages wouldn't add anything.
++            _warn_if_file_doesnt_exist.has_logged_missing_file_error = True
++            log_warning(f""">>> A source file you compile doesn't (yet) exist: {source_file}
++    It's probably a generated file, and you haven't yet run a build to generate it.
++    That's OK; your code doesn't even have to compile for this tool to work.
++    If you can, though, you might want to run a build of your code.
++        That way everything is generated, browsable and indexed for autocomplete.
++    However, if you have *already* built your code, and generated the missing file...
++        Please make sure you're supplying this tool with the same flags you use to build.
++        You can either use a refresh_compile_commands rule or the special -- syntax. Please see the README.
++        [Supplying flags normally won't work. That just causes this tool to be built with those flags.]
++    Continuing gracefully...""")
++        return True
++    return False
++_warn_if_file_doesnt_exist.has_logged_missing_file_error = False
++
++
+ def _get_files(compile_action):
+     """Gets the ({source files}, {header files}) clangd should be told the command applies to."""
+ 
++    # If we've got swift action just return sources
++    if compile_action.mnemonic == 'SwiftCompile':
++        source_files = set(arg for arg in compile_action.arguments if arg.endswith('.swift'))
++        for source_file in source_files:
++            _warn_if_file_doesnt_exist(source_file)
++
++        return source_files, set()
++
++    # Getting the source file is a little t
+     # Getting the source file is a little trickier than it might seem.
+ 
+     # First, we do the obvious thing: Filter args to those that look like source files.
+-    source_file_candidates = [arg for arg in compile_action.arguments if not arg.startswith('-') and arg.endswith(_get_files.source_extensions)]
++    source_file_candidates = [arg for arg in compile_action.arguments if not arg.startswith('-') and arg.endswith(_get_files.c_family_source_extensions)]
+     assert source_file_candidates, f"No source files found in compile args: {compile_action.arguments}.\nPlease file an issue with this information!"
+     source_file = source_file_candidates[0]
+ 
+@@ -585,22 +617,10 @@ def _get_files(compile_action):
+             source_index = compile_action.arguments.index('/c') + 1
+ 
+         source_file = compile_action.arguments[source_index]
+-        assert source_file.endswith(_get_files.source_extensions), f"Source file candidate, {source_file}, seems to be wrong.\nSelected from {compile_action.arguments}.\nPlease file an issue with this information!"
++        assert source_file.endswith(_get_files.c_family_source_extensions), f"Source file candidate, {source_file}, seems to be wrong.\nSelected from {compile_action.arguments}.\nPlease file an issue with this information!"
+ 
+     # Warn gently about missing files
+-    if not os.path.isfile(source_file):
+-        if not _get_files.has_logged_missing_file_error: # Just log once; subsequent messages wouldn't add anything.
+-            _get_files.has_logged_missing_file_error = True
+-            log_warning(f""">>> A source file you compile doesn't (yet) exist: {source_file}
+-    It's probably a generated file, and you haven't yet run a build to generate it.
+-    That's OK; your code doesn't even have to compile for this tool to work.
+-    If you can, though, you might want to run a build of your code with --keep_going.
+-        That way everything possible is generated, browsable and indexed for autocomplete.
+-    However, if you have *already* built your code, and generated the missing file...
+-        Please make sure you're supplying this tool with the same flags you use to build.
+-        You can either use a refresh_compile_commands rule or the special -- syntax. Please see the README.
+-        [Supplying flags normally won't work. That just causes this tool to be built with those flags.]
+-    Continuing gracefully...""")
++    if _warn_if_file_doesnt_exist(source_file):
+         return {source_file}, set()
+ 
+     # Note: We need to apply commands to headers and sources.
+@@ -629,7 +649,6 @@ def _get_files(compile_action):
+         compile_action.arguments.insert(1, lang_flag)
+ 
+     return {source_file}, header_files
+-_get_files.has_logged_missing_file_error = False
+ # Setup extensions and flags for the whole C-language family.
+ # Clang has a list: https://github.com/llvm/llvm-project/blob/b9f3b7f89a4cb4cf541b7116d9389c73690f78fa/clang/lib/Driver/Types.cpp#L293
+ _get_files.c_source_extensions = ('.c', '.i')
+@@ -641,7 +660,6 @@ _get_files.opencl_source_extensions = ('.cl',)
+ _get_files.openclxx_source_extensions = ('.clcpp',)
+ _get_files.assembly_source_extensions = ('.s', '.asm')
+ _get_files.assembly_needing_c_preprocessor_source_extensions = ('.S',)
+-_get_files.source_extensions = _get_files.c_source_extensions + _get_files.cpp_source_extensions + _get_files.objc_source_extensions + _get_files.objcpp_source_extensions + _get_files.cuda_source_extensions + _get_files.opencl_source_extensions + _get_files.openclxx_source_extensions + _get_files.assembly_source_extensions + _get_files.assembly_needing_c_preprocessor_source_extensions
+ _get_files.extensions_to_language_args = { # Note that clangd fails on the --language or -ObjC or -ObjC++ forms. See https://github.com/clangd/clangd/issues/1173#issuecomment-1226847416
+     _get_files.c_source_extensions: '-xc',
+     _get_files.cpp_source_extensions: '-xc++',
+@@ -654,6 +672,8 @@ _get_files.extensions_to_language_args = { # Note that clangd fails on the --lan
+     _get_files.assembly_needing_c_preprocessor_source_extensions: '-xassembler-with-cpp',
+ }
+ _get_files.extensions_to_language_args = {ext : flag for exts, flag in _get_files.extensions_to_language_args.items() for ext in exts} # Flatten map for easier use
++_get_files.c_family_source_extensions = _get_files.c_source_extensions + _get_files.cpp_source_extensions + _get_files.objc_source_extensions + _get_files.objcpp_source_extensions + _get_files.cuda_source_extensions + _get_files.opencl_source_extensions + _get_files.openclxx_source_extensions + _get_files.assembly_source_extensions + _get_files.assembly_needing_c_preprocessor_source_extensions
++_get_files.source_extensions = _get_files.c_families_source_extensions + '.swift'
+ 
+ 
+ @functools.lru_cache(maxsize=None)
+@@ -674,17 +694,25 @@ def _get_apple_SDKROOT(SDK_name: str):
+     # Traditionally stored in SDKROOT environment variable, but not provided by Bazel. See https://github.com/bazelbuild/bazel/issues/12852
+ 
+ 
+-def _get_apple_platform(compile_args: typing.List[str]):
++def _get_apple_platform(compile_action):
+     """Figure out which Apple platform a command is for.
+ 
+     Is the name used by Xcode in the SDK files, not the marketing name.
+     e.g. iPhoneOS, not iOS.
+     """
+     # A bit gross, but Bazel specifies the platform name in one of the include paths, so we mine it from there.
++    compile_args = compile_action.arguments
+     for arg in compile_args:
+         match = re.search('/Platforms/([a-zA-Z]+).platform/Developer/', arg)
+         if match:
+             return match.group(1)
++    if getattr(compile_action, 'environmentVariables', None):
++        match = next(
++            filter(lambda x: x.key == "APPLE_SDK_PLATFORM", compile_action.environmentVariables),
++            None
++        )
++        if match:
++            return match.value
+     return None
+ 
+ 
+@@ -696,18 +724,21 @@ def _get_apple_DEVELOPER_DIR():
+     # Traditionally stored in DEVELOPER_DIR environment variable, but not provided by Bazel. See https://github.com/bazelbuild/bazel/issues/12852
+ 
+ 
+-def _apple_platform_patch(compile_args: typing.List[str]):
++def _apple_platform_patch(compile_action):
+     """De-Bazel the command into something clangd can parse.
+ 
+     This function has fixes specific to Apple platforms, but you should call it on all platforms. It'll determine whether the fixes should be applied or not.
+     """
++    compile_args = compile_action.arguments
+     # Bazel internal environment variable fragment that distinguishes Apple platforms that need unwrapping.
+         # Note that this occurs in the Xcode-installed wrapper, but not the CommandLineTools wrapper, which works fine as is.
+     if any('__BAZEL_XCODE_' in arg for arg in compile_args):
+         # Undo Bazel's Apple platform compiler wrapping.
+         # Bazel wraps the compiler as `external/local_config_cc/wrapped_clang` and exports that wrapped compiler in the proto. However, we need a clang call that clangd can introspect. (See notes in "how clangd uses compile_commands.json" in ImplementationReadme.md for more.)
+         # Removing the wrapper is also important because Bazel's Xcode (but not CommandLineTools) wrapper crashes if you don't specify particular environment variables (replaced below). We'd need the wrapper to be invokable by clangd's --query-driver if we didn't remove the wrapper.
+-        compile_args[0] = 'clang'
++
++        if compile_action.mnemonic != 'SwiftCompile':
++            compile_args[0] = 'clang'
+ 
+         # We have to manually substitute out Bazel's macros so clang can parse the command
+         # Code this mirrors is in https://github.com/bazelbuild/bazel/blob/master/tools/osx/crosstool/wrapped_clang.cc
+@@ -716,15 +747,41 @@ def _apple_platform_patch(compile_args: typing.List[str]):
+         # We also have to manually figure out the values of SDKROOT and DEVELOPER_DIR, since they're missing from the environment variables Bazel provides.
+         # Filed Bazel issue about the missing environment variables: https://github.com/bazelbuild/bazel/issues/12852
+         compile_args = [arg.replace('__BAZEL_XCODE_DEVELOPER_DIR__', _get_apple_DEVELOPER_DIR()) for arg in compile_args]
+-        apple_platform = _get_apple_platform(compile_args)
++        apple_platform = _get_apple_platform(compile_action)
+         assert apple_platform, f"Apple platform not detected in CMD: {compile_args}"
+         compile_args = [arg.replace('__BAZEL_XCODE_SDKROOT__', _get_apple_SDKROOT(apple_platform)) for arg in compile_args]
+ 
+     return compile_args
+ 
+ 
+-def _all_platform_patch(compile_args: typing.List[str]):
++def _swift_patch(compile_action):
++    """De-Bazel the command into something sourecekit-lsp can parse.
++
++    This function has fixes specific to Swift, but you should call it on all platforms. It'll determine whether the fixes should be applied or not.
++    """
++
++    compile_args = compile_action.arguments
++    if compile_action.mnemonic == 'SwiftCompile':
++        # rules_swift add a worker for wrapping if enable --persistent_worker flag (https://bazel.build/remote/persistent)
++        # https://github.com/bazelbuild/rules_swift/blob/master/swift/internal/actions.bzl#L236
++        # We need to remove it (build_bazel_rules_swift/tools/worker/worker)
++        while len(compile_args) > 0 and (not 'swiftc' in compile_args[0]):
++            compile_args.pop(0)
++
++        assert len(compile_args) > 0, "No compiler found in swift_path"
++        compile_args[0] = 'swiftc'
++
++        # Remove -Xwrapped-swift introduced by rules_swift
++        compile_args = [arg for arg in compile_args if not arg.startswith('-Xwrapped-swift')]
++
++    return compile_args
++
++
++def _all_platform_patch(compile_action):
+     """Apply de-Bazeling fixes to the compile command that are shared across target platforms."""
++
++    compile_args = compile_action.arguments
++
+     # clangd writes module cache files to the wrong place
+     # Without this fix, you get tons of module caches dumped into the VSCode root folder.
+     # Filed clangd issue at: https://github.com/clangd/clangd/issues/655
+@@ -759,22 +816,29 @@ def _all_platform_patch(compile_args: typing.List[str]):
+     return compile_args
+ 
+ 
+-def _get_cpp_command_for_files(compile_action):
++def _get_command_for_files(compile_action):
+     """Reformat compile_action into a compile command clangd can understand.
+ 
+     Undo Bazel-isms and figures out which files clangd should apply the command to.
+     """
++    (compile_action, event, should_stop_lambda) = args
++    if event.is_set():
++        return set(), set(), []
++
+     # Patch command by platform
+-    compile_action.arguments = _all_platform_patch(compile_action.arguments)
+-    compile_action.arguments = _apple_platform_patch(compile_action.arguments)
++    compile_action.arguments = _all_platform_patch(compile_action)
++    compile_action.arguments = _apple_platform_patch(compile_action)
++    compile_action.arguments = _swift_patch(compile_action)
+     # Android and Linux and grailbio LLVM toolchains: Fine as is; no special patching needed.
+ 
+     source_files, header_files = _get_files(compile_action)
+ 
++    if not event.is_set() and should_stop_lambda(source_files, header_files):
++        event.set()
+     return source_files, header_files, compile_action.arguments
+ 
+ 
+-def _convert_compile_commands(aquery_output):
++def _convert_compile_commands(aquery_output, should_stop_lambda):
+     """Converts from Bazel's aquery format to de-Bazeled compile_commands.json entries.
+ 
+     Input: jsonproto output from aquery, pre-filtered to (Objective-)C(++) compile actions for a given build.
+@@ -798,8 +862,8 @@ def _convert_compile_commands(aquery_output):
+     with concurrent.futures.ThreadPoolExecutor(
+         max_workers=min(32, (os.cpu_count() or 1) + 4) # Backport. Default in MIN_PY=3.8. See "using very large resources implicitly on many-core machines" in https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor
+     ) as threadpool:
+-        outputs = threadpool.map(_get_cpp_command_for_files, aquery_output.actions)
+-
++        event = threading.Event()
++        outputs = threadpool.map(_get_command_for_files, map(lambda action: (action, event, should_stop_lambda), aquery_output.actions))
+     # Yield as compile_commands.json entries
+     header_files_already_written = set()
+     for source_files, header_files, compile_command_args in outputs:
+@@ -825,16 +889,100 @@ def _convert_compile_commands(aquery_output):
+ 
+ 
+ def _get_commands(target: str, flags: str):
+-    """Yields compile_commands.json entries for a given target and flags, gracefully tolerating errors."""
++    """Return compile_commands.json entries for a given target and flags, gracefully tolerating errors."""
++    lock = threading.RLock()
++    counter = itertools.count()
++    def _should_stop(headers, file_path):
++        if file_path:
++            with lock:
++                tried_count = next(counter)
++            if tried_count >= BAZEL_INTERNAL_MAX_HEADER_SEARCH_COUNT:
++                log_warning(f""">>> Bazel lists no applicable compile commands for {file_path} in {target} under {tried_count} Attempt.""")
++                return True
++            return any(header.endswith(file_path) for header in headers)
++        return False
++
++    def _get_commands(target_statment, file_path):
++        aquery_args = [
++            'bazel',
++            'aquery',
++            # Aquery docs if you need em: https://docs.bazel.build/versions/master/aquery.html
++            # Aquery output proto reference: https://github.com/bazelbuild/bazel/blob/master/src/main/protobuf/analysis_v2.proto
++            # One bummer, not described in the docs, is that aquery filters over *all* actions for a given target, rather than just those that would be run by a build to produce a given output. This mostly isn't a problem, but can sometimes surface extra, unnecessary, misconfigured actions. Chris has emailed the authors to discuss and filed an issue so anyone reading this could track it: https://github.com/bazelbuild/bazel/issues/14156.
++            f"mnemonic('(Objc|Cpp|Swift)Compile', {target_statment})",
++            # We switched to jsonproto instead of proto because of https://github.com/bazelbuild/bazel/issues/13404. We could change back when fixed--reverting most of the commit that added this line and tweaking the build file to depend on the target in that issue. That said, it's kinda nice to be free of the dependency, unless (OPTIMNOTE) jsonproto becomes a performance bottleneck compated to binary protos.
++            '--output=jsonproto',
++            # We'll disable artifact output for efficiency, since it's large and we don't use them. Small win timewise, but dramatically less json output from aquery.
++            '--include_artifacts=false',
++            # Shush logging. Just for readability.
++            '--ui_event_filters=-info',
++            '--noshow_progress',
++            # Disable param files, which would obscure compile actions
++            # Mostly, people enable param files on Windows to avoid the relatively short command length limit.
++                # For more, see compiler_param_file in https://bazel.build/docs/windows
++                # They are, however, technically supported on other platforms/compilers.
++            # That's all well and good, but param files would prevent us from seeing compile actions before the param files had been generated by compilation.
++            # Since clangd has no such length limit, we'll disable param files for our aquery run.
++            '--features=-compiler_param_file',
++            # Disable layering_check during, because it causes large-scale dependence on generated module map files that prevent header extraction before their generation
++                # For more context, see https://github.com/hedronvision/bazel-compile-commands-extractor/issues/83
++                # If https://github.com/clangd/clangd/issues/123 is resolved and we're not doing header extraction, we could try removing this, checking that there aren't erroneous red squigglies squigglies before the module maps are generated.
++                # If Bazel starts supporting modules (https://github.com/bazelbuild/bazel/issues/4005), we'll probably need to make changes that subsume this.
++            '--features=-layering_check',
++        ] + additional_flags
++
++        aquery_process = subprocess.run(
++            aquery_args,
++            capture_output=True,
++            encoding=locale.getpreferredencoding(),
++            check=False, # We explicitly ignore errors from `bazel aquery` and carry on.
++        )
++
++
++        # Filter aquery error messages to just those the user should care about.
++        missing_targets_warning: typing.Pattern[str] = re.compile(r'(\(\d+:\d+:\d+\) )?(\033\[[\d;]+m)?WARNING: (\033\[[\d;]+m)?Targets were missing from graph:') # Regex handles --show_timestamps and --color=yes. Could use "in" if we ever need more flexibility.
++        for line in aquery_process.stderr.splitlines():
++            # Shush known warnings about missing graph targets.
++            # The missing graph targets are not things we want to introspect anyway.
++            # Tracking issue https://github.com/bazelbuild/bazel/issues/13007.
++            if missing_targets_warning.match(line):
++                continue
++
++            print(line, file=sys.stderr)
++
++
++        # Parse proto output from aquery
++        try:
++            # object_hook -> SimpleNamespace allows object.member syntax, like a proto, while avoiding the protobuf dependency
++            parsed_aquery_output = json.loads(aquery_process.stdout, object_hook=lambda d: types.SimpleNamespace(**d))
++        except json.JSONDecodeError:
++            print("Bazel aquery failed. Command:", aquery_args, file=sys.stderr)
++            log_warning(f">>> Failed extracting commands for {target}\n    Continuing gracefully...")
++            return []
++
++        if not getattr(parsed_aquery_output, 'actions', None): # Unifies cases: No actions (or actions list is empty)
++            return []
++
++        return _convert_compile_commands(parsed_aquery_output, lambda _, headers: _should_stop(headers, file_path))
++
++
+     # Log clear completion messages
+     log_info(f">>> Analyzing commands used in {target}")
+ 
+-    additional_flags = shlex.split(flags) + sys.argv[1:]
++    # Pass along all arguments to aquery, except for --file=
++    additional_flags = shlex.split(flags) + [arg for arg in sys.argv[1:] if not arg.startswith('--file=')]
++    file_flags = [arg[len('--file='):] for arg in sys.argv[1:] if arg.startswith('--file=')]
++    if len(file_flags) > 1:
++        log_error(">>> At most one --file flag is supported.")
++        sys.exit(1)
++    if any(arg.startswith('--file') for arg in additional_flags):
++        log_error(">>> Only the --file=<file_target> form is supported.")
++        sys.exit(1)
+ 
+     # Detect anything that looks like a build target in the flags, and issue a warning.
+-    # Note that positional arguments after -- are all interpreted as target patterns. (If it's at the end, then no worries.)
++    # Note that positional arguments after -- are all interpreted as target patterns.
+     # And that we have to look for targets. checking for a - prefix is not enough. Consider the case of `-c opt` leading to a false positive
+-    if ('--' in additional_flags[:-1]
++    if ('--' in additional_flags
+         or any(re.match(r'-?(@|:|//)', f) for f in additional_flags)):
+         log_warning(""">>> The flags you passed seem to contain targets.
+     Try adding them as targets in your refresh_compile_commands rather than flags.
+@@ -847,79 +995,46 @@ def _get_commands(target: str, flags: str):
+     Try adding them as flags in your refresh_compile_commands rather than targets.
+     In a moment, Bazel will likely fail to parse.""")
+ 
++    compile_commands = []
+     # First, query Bazel's C-family compile actions for that configured target
+     target_statment = f'deps({target})'
+-    if {exclude_external_sources}:
+-        # For efficiency, have bazel filter out external targets (and therefore actions) before they even get turned into actions or serialized and sent to us. Note: this is a different mechanism than is used for excluding just external headers.
+-        target_statment = f"filter('^(//|@//)',{target_statment})"
+-    aquery_args = [
+-        'bazel',
+-        'aquery',
+-        # Aquery docs if you need em: https://docs.bazel.build/versions/master/aquery.html
+-        # Aquery output proto reference: https://github.com/bazelbuild/bazel/blob/master/src/main/protobuf/analysis_v2.proto
+-        # One bummer, not described in the docs, is that aquery filters over *all* actions for a given target, rather than just those that would be run by a build to produce a given output. This mostly isn't a problem, but can sometimes surface extra, unnecessary, misconfigured actions. Chris has emailed the authors to discuss and filed an issue so anyone reading this could track it: https://github.com/bazelbuild/bazel/issues/14156.
+-        f"mnemonic('(Objc|Cpp)Compile',{target_statment})",
+-        # We switched to jsonproto instead of proto because of https://github.com/bazelbuild/bazel/issues/13404. We could change back when fixed--reverting most of the commit that added this line and tweaking the build file to depend on the target in that issue. That said, it's kinda nice to be free of the dependency, unless (OPTIMNOTE) jsonproto becomes a performance bottleneck compated to binary protos.
+-        '--output=jsonproto',
+-        # We'll disable artifact output for efficiency, since it's large and we don't use them. Small win timewise, but dramatically less json output from aquery.
+-        '--include_artifacts=false',
+-        # Shush logging. Just for readability.
+-        '--ui_event_filters=-info',
+-        '--noshow_progress',
+-        # Disable param files, which would obscure compile actions
+-        # Mostly, people enable param files on Windows to avoid the relatively short command length limit.
+-            # For more, see compiler_param_file in https://bazel.build/docs/windows
+-            # They are, however, technically supported on other platforms/compilers.
+-        # That's all well and good, but param files would prevent us from seeing compile actions before the param files had been generated by compilation.
+-        # Since clangd has no such length limit, we'll disable param files for our aquery run.
+-        '--features=-compiler_param_file',
+-        # Disable layering_check during, because it causes large-scale dependence on generated module map files that prevent header extraction before their generation
+-            # For more context, see https://github.com/hedronvision/bazel-compile-commands-extractor/issues/83
+-            # If https://github.com/clangd/clangd/issues/123 is resolved and we're not doing header extraction, we could try removing this, checking that there aren't erroneous red squigglies squigglies before the module maps are generated.
+-            # If Bazel starts supporting modules (https://github.com/bazelbuild/bazel/issues/4005), we'll probably need to make changes that subsume this.
+-        '--features=-layering_check',
+-    ] + additional_flags
+-
+-    aquery_process = subprocess.run(
+-        aquery_args,
+-        capture_output=True,
+-        encoding=locale.getpreferredencoding(),
+-        check=False, # We explicitly ignore errors from `bazel aquery` and carry on.
+-    )
+ 
++    if file_flags:
++        file_path = file_flags[0]
++        found = False
++        target_statment_canidates = []
++        if file_flags[0].endswith(_get_files.source_extensions):
++            target_statment_canidates.append(f"inputs('{re.escape(file_path)}', {target_statment})")
++        else:
++            fname = os.path.basename(file_path)
++            target_statment_canidates.extend([
++                f"let v = {target_statment} in attr(hdrs, '{fname}', $v) + attr(srcs, '{fname}', $v)",
++                f"inputs('{re.escape(file_path)}', {target_statment})",
++                f'deps({target})',
++            ])
++
++        for target_statment in target_statment_canidates:
++            compile_commands.extend( _get_commands(target_statment, file_path))
++            if any(command['file'].endswith(file_path) for command in reversed(compile_commands)):
++                found = True
++                break
++        if not found:
++            log_warning(f""">>> Bazel lists no applicable compile commands for {file_path} in {target}.
++        Continuing gracefully...""")
+ 
+-    # Filter aquery error messages to just those the user should care about.
+-    missing_targets_warning: typing.Pattern[str] = re.compile(r'(\(\d+:\d+:\d+\) )?(\033\[[\d;]+m)?WARNING: (\033\[[\d;]+m)?Targets were missing from graph:') # Regex handles --show_timestamps and --color=yes. Could use "in" if we ever need more flexibility.
+-    for line in aquery_process.stderr.splitlines():
+-        # Shush known warnings about missing graph targets.
+-        # The missing graph targets are not things we want to introspect anyway.
+-        # Tracking issue https://github.com/bazelbuild/bazel/issues/13007.
+-        if missing_targets_warning.match(line):
+-            continue
+-
+-        print(line, file=sys.stderr)
+-
+-
+-    # Parse proto output from aquery
+-    try:
+-        # object_hook -> SimpleNamespace allows object.member syntax, like a proto, while avoiding the protobuf dependency
+-        parsed_aquery_output = json.loads(aquery_process.stdout, object_hook=lambda d: types.SimpleNamespace(**d))
+-    except json.JSONDecodeError:
+-        print("Bazel aquery failed. Command:", aquery_args, file=sys.stderr)
+-        log_warning(f">>> Failed extracting commands for {target}\n    Continuing gracefully...")
+-        return
+-
+-    if not getattr(parsed_aquery_output, 'actions', None): # Unifies cases: No actions (or actions list is empty)
+-        log_warning(f""">>> Bazel lists no applicable compile commands for {target}
+-    If this is a header-only library, please instead specify a test or binary target that compiles it (search "header-only" in README.md).
+-    Continuing gracefully...""")
+-        return
+-
+-    yield from _convert_compile_commands(parsed_aquery_output)
+-
++    else:
++        if {exclude_external_sources}:
++            # For efficiency, have bazel filter out external targets (and therefore actions) before they even get turned into actions or serialized and sent to us. Note: this is a different mechanism than is used for excluding just external headers.
++            target_statment = f"filter('^(//|@//)',{target_statment})"
++        compile_commands.extend(_get_commands(target_statment, None))
++        if len(compile_commands) == 0:
++            log_warning(f""">>> Bazel lists no applicable compile commands for {target}
++        If this is a header-only library, please instead specify a test or binary target that compiles it (search "header-only" in README.md).
++        Continuing gracefully...""")
+ 
+     # Log clear completion messages
+     log_success(f">>> Finished extracting commands for {target}")
++    return compile_commands
+ 
+ 
+ def _ensure_external_workspaces_link_exists():
+@@ -1055,6 +1170,18 @@ if __name__ == '__main__':
+     for (target, flags) in target_flag_pairs:
+         compile_command_entries.extend(_get_commands(target, flags))
+ 
++    # --file triggers incremental update of compile_commands.json
++    if any(arg.startswith('--file=') for arg in sys.argv[1:]) and os.path.isfile('compile_commands.json'):
++        previous_compile_command_entries = []
++        try:
++            with open('compile_commands.json') as compile_commands_file:
++                previous_compile_command_entries = json.load(compile_commands_file)
++        except:
++            log_warning(">>> Couldn't read previous compile_commands.json. Overwriting instead of merging...")
++        else:
++            updated_files = set(entry['file'] for entry in compile_command_entries)
++            compile_command_entries += [entry for entry in previous_compile_command_entries if entry['file'] not in updated_files]
++
+     # Chain output into compile_commands.json
+     with open('compile_commands.json', 'w') as output_file:
+         json.dump(
+diff --git a/refresh_compile_commands.bzl b/refresh_compile_commands.bzl
+index b9c5d32..70cf8f5 100644
+--- a/refresh_compile_commands.bzl
++++ b/refresh_compile_commands.bzl
+@@ -49,6 +49,8 @@ refresh_compile_commands(
+         # exclude_headers = "external",
+     # Still not fast enough?
+         # Make sure you're specifying just the targets you care about by setting `targets`, above.
++    # That's still not enough; I'm working on a huge codebase!
++        # This tool supports a fast, incremental mode that can be used to add/update commands as individual files are opened. If you'd be willing to collaborate on writing a simple editor plugin invokes this tool on file open, please write in! (And see --file flag in refresh.template.py)
+ ```
+ """
+ 
